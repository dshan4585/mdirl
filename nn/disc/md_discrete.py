import tensorflow as tf
from const_discrete import reg_type, na, q
from util.tf_util_discrete import *
from util.pd_discrete import ent, tent,

from util.pd_discrete import rf as r
from util.pd_discrete import breg as D

class MirrorDescentDiscrete:
  def __init__(self, Ï€):
    self.Ï€ = Ï€
    rinit = tf.zeros(na,tf.float32)
    tinit = tf.zeros(na,tf.float32)
    self.rlogit = tf.Variable(rinit, dtype=tf.float32)
    self.tlogit = tf.Variable(tinit, dtype=tf.float32)
    self.vars = [self.rlogit, self.tlogit]
    self.updater()

  @tf.function
  def rwd(self, a):
    return r(a,self.rlogit)

  @tf.function
  def loss(self, aÏ€, aE, Î±):
    nÏ€ = shape(sÏ€)[0]
    nE = shape(sE)[0]
    lÏ€ = zeros(nÏ€)
    lE = ones(nE)
    l = concat([lÏ€,lE],0)
    a = concat([aÏ€,aE],0)

    logit = self.Ï€.logit
    rlogit = self.rlogit
    tlogit = self.tlogit

    f = logp(a,tlogit) - logp(a,logit)
    rÏ€, rE = split(r(a,rlogit),2)

    loss = 2*ğ”¼(bce(l,f))

    rloss = ğ”¼((1/Î±)*D(rlogit,no_grad(tdist)) +\
        ((Î±-1)/Î±)*D(rlogit,dist))

    return loss+rloss, rÏ€, rE

  def updater(self):
    for Ï€_var, r_var in zip(self.Ï€.vars, self.r_vars):
      r_var.assign(Ï€_var)